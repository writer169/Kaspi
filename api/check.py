# api/check.py - –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è
from http.server import BaseHTTPRequestHandler
import requests
import json
from datetime import datetime
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import os
from urllib.parse import urlparse, parse_qs
from bs4 import BeautifulSoup

# –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
KASPI_URL = os.getenv("KASPI_URL")
EMAIL_FROM = os.getenv("EMAIL_FROM")
EMAIL_TO = os.getenv("EMAIL_TO")
EMAIL_PASSWORD = os.getenv("EMAIL_PASSWORD")
API_KEY = os.getenv("API_KEY")
SCRAPER_API_KEY = os.getenv("SCRAPER_API_KEY")
SEND_EMAIL = os.getenv("SEND_EMAIL", "true").lower() == "true"
USE_SCRAPER_API = os.getenv("USE_SCRAPER_API", "true").lower() == "true"

def log_message(message, level="INFO"):
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    return f"[{timestamp}] [{level}] {message}\n"

def send_email_notification(subject, body):
    if not SEND_EMAIL or not all([EMAIL_FROM, EMAIL_TO, EMAIL_PASSWORD]):
        return "Email –æ—Ç–∫–ª—é—á–µ–Ω –∏–ª–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"
    
    try:
        msg = MIMEMultipart("alternative")
        msg["Subject"] = subject
        msg["From"] = EMAIL_FROM
        msg["To"] = EMAIL_TO
        
        html_body = f"""
        <html>
          <body style="font-family: Arial, sans-serif; padding: 20px;">
            <h2 style="color: #4CAF50;">üéâ {subject}</h2>
            <p style="font-size: 16px;">{body}</p>
            <hr style="margin: 20px 0;">
            <p>
              <a href="{KASPI_URL}" 
                 style="background-color: #4CAF50; color: white; 
                        padding: 12px 24px; text-decoration: none; 
                        border-radius: 5px; display: inline-block;">
                –û—Ç–∫—Ä—ã—Ç—å –Ω–∞ Kaspi.kz
              </a>
            </p>
            <p style="color: #666; font-size: 12px; margin-top: 20px;">
              {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
            </p>
          </body>
        </html>
        """
        
        msg.attach(MIMEText(body, "plain", "utf-8"))
        msg.attach(MIMEText(html_body, "html", "utf-8"))
        
        server = smtplib.SMTP_SSL("smtp.gmail.com", 465)
        server.login(EMAIL_FROM, EMAIL_PASSWORD)
        server.sendmail(EMAIL_FROM, EMAIL_TO, msg.as_string())
        server.quit()
        
        return "‚úÖ Email –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω"
    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ email: {str(e)}"

def parse_product_data_from_soup(soup, logs):
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥—É–∫—Ç–µ –∏–∑ HTML.
    –ò—â–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π JSON-LD –±–ª–æ–∫ —Ç–∏–ø–∞ "Product".
    """
    all_data_blocks = soup.find_all("script", {"type": "application/ld+json"})
    
    if not all_data_blocks:
        logs.append(log_message("JSON-LD –±–ª–æ–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ", "ERROR"))
        return None

    product_data_json = None
    for block in all_data_blocks:
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º .string, —Ç.–∫. .text –º–æ–∂–µ—Ç –æ–±—ä–µ–¥–∏–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–µ–≥–æ–≤
            data = json.loads(block.string)
            # –ì–ª–∞–≤–Ω–æ–µ —É—Å–ª–æ–≤–∏–µ: –∏—â–µ–º –±–ª–æ–∫, –∫–æ—Ç–æ—Ä—ã–π –æ–ø–∏—Å—ã–≤–∞–µ—Ç –∏–º–µ–Ω–Ω–æ "Product"
            if data.get("@type") == "Product":
                product_data_json = data
                logs.append(log_message("‚úÖ –ù–∞–π–¥–µ–Ω JSON-LD –±–ª–æ–∫ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Ç–æ–≤–∞—Ä–µ"))
                break 
        except (json.JSONDecodeError, AttributeError):
            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∏–ª–∏ –ø—É—Å—Ç—ã–µ JSON-–±–ª–æ–∫–∏
            continue

    if not product_data_json:
        logs.append(log_message("JSON-LD –±–ª–æ–∫ —Ç–∏–ø–∞ 'Product' –Ω–µ –Ω–∞–π–¥–µ–Ω", "ERROR"))
        return None

    return product_data_json

def check_with_scraper_api():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ ScraperAPI - –æ–±—Ö–æ–¥–∏—Ç –ª—é–±—É—é –∑–∞—â–∏—Ç—É"""
    logs = []
    logs.append(log_message("–ò—Å–ø–æ–ª—å–∑—É–µ–º ScraperAPI –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏"))
    
    if not SCRAPER_API_KEY:
        logs.append(log_message("SCRAPER_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω", "ERROR"))
        return {"success": False, "logs": logs, "error": "ScraperAPI key not configured"}
    
    try:
        api_url = "https://api.scraperapi.com"
        params = { "api_key": SCRAPER_API_KEY, "url": KASPI_URL }
        
        logs.append(log_message("–û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ ScraperAPI..."))
        response = requests.get(api_url, params=params, timeout=60)
        logs.append(log_message(f"–°—Ç–∞—Ç—É—Å: {response.status_code}"))
        
        if response.status_code != 200:
            error_text = response.text[:200] if response.text else "No error message"
            logs.append(log_message(f"ScraperAPI error: {error_text}", "ERROR"))
            return {"success": False, "logs": logs, "error": f"ScraperAPI returned {response.status_code}"}
        
        logs.append(log_message("‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω–∞, –ø–∞—Ä—Å–∏–º HTML..."))
        soup = BeautifulSoup(response.text, "html.parser")
        
        # === –ò–ó–ú–ï–ù–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê –ü–ê–†–°–ò–ù–ì–ê ===
        data = parse_product_data_from_soup(soup, logs)
        if not data:
            return {"success": False, "logs": logs, "error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥—É–∫—Ç–µ"}

        product_name = data.get("name", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä")
        offers = data.get("offers", [])
        price, currency, availability = "–ù–µ —É–∫–∞–∑–∞–Ω–∞", "", ""

        # –ò—â–µ–º –∞–∫—Ç—É–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤ —Å–ø–∏—Å–∫–µ, —Ç–∞–∫ –∫–∞–∫ "offers" - —ç—Ç–æ –º–∞—Å—Å–∏–≤
        for offer in offers:
            if offer.get("@type") == "Offer":
                price = offer.get("price", "–ù–µ —É–∫–∞–∑–∞–Ω–∞")
                currency = offer.get("priceCurrency", "")
                availability = offer.get("availability", "")
                break # –ù–∞—à–ª–∏, –≤—ã—Ö–æ–¥–∏–º

        in_stock = "InStock" in availability
        # ==================================
        
        logs.append(log_message(f"üì¶ –¢–æ–≤–∞—Ä: {product_name}"))
        logs.append(log_message(f"üí∞ –¶–µ–Ω–∞: {price} {currency}"))
        logs.append(log_message(f"üìä –°—Ç–∞—Ç—É—Å: {availability}"))
        
        if in_stock:
            logs.append(log_message("‚úÖ –¢–û–í–ê–† –í –ù–ê–õ–ò–ß–ò–ò!", "SUCCESS"))
        else:
            logs.append(log_message("‚ùå –¢–æ–≤–∞—Ä–∞ –Ω–µ—Ç –≤ –Ω–∞–ª–∏—á–∏–∏", "INFO"))
        
        return {
            "success": True,
            "in_stock": in_stock,
            "product_name": product_name,
            "price": f"{price} {currency}",
            "availability": availability,
            "method": "scraperapi",
            "logs": logs
        }
        
    except requests.exceptions.Timeout:
        logs.append(log_message("–¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –∫ ScraperAPI", "ERROR"))
        return {"success": False, "logs": logs, "error": "ScraperAPI timeout"}
    except Exception as e:
        logs.append(log_message(f"–û—à–∏–±–∫–∞: {str(e)}", "ERROR"))
        return {"success": False, "logs": logs, "error": str(e)}

def check_direct():
    """–ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å (–∑–∞–ø–∞—Å–Ω–æ–π –º–µ—Ç–æ–¥)"""
    logs = []
    logs.append(log_message(f"–ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å –∫ Kaspi"))
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
        "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7"
    }
    
    try:
        session = requests.Session()
        session.headers.update(headers)
        
        logs.append(log_message("–û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å..."))
        r = session.get(KASPI_URL, timeout=20, allow_redirects=True)
        logs.append(log_message(f"–°—Ç–∞—Ç—É—Å: {r.status_code}"))
        
        if r.status_code != 200:
            return {"success": False, "logs": logs, "error": f"–°—Ç–∞—Ç—É—Å {r.status_code}"}
        
        soup = BeautifulSoup(r.text, "html.parser")
        
        # === –ò–ó–ú–ï–ù–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê –ü–ê–†–°–ò–ù–ì–ê ===
        data = parse_product_data_from_soup(soup, logs)
        if not data:
            return {"success": False, "logs": logs, "error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥—É–∫—Ç–µ"}

        product_name = data.get("name", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä")
        offers = data.get("offers", [])
        price, currency, availability = "–ù–µ —É–∫–∞–∑–∞–Ω–∞", "", ""

        for offer in offers:
            if offer.get("@type") == "Offer":
                price = offer.get("price", "–ù–µ —É–∫–∞–∑–∞–Ω–∞")
                currency = offer.get("priceCurrency", "")
                availability = offer.get("availability", "")
                break
        
        in_stock = "InStock" in availability
        # ==================================
        
        logs.append(log_message(f"–¢–æ–≤–∞—Ä: {product_name}"))
        logs.append(log_message(f"–¶–µ–Ω–∞: {price} {currency}"))
        logs.append(log_message("‚úÖ –í –Ω–∞–ª–∏—á–∏–∏" if in_stock else "‚ùå –ù–µ—Ç –≤ –Ω–∞–ª–∏—á–∏–∏"))
        
        return {
            "success": True,
            "in_stock": in_stock,
            "product_name": product_name,
            "price": f"{price} {currency}",
            "availability": availability,
            "method": "direct",
            "logs": logs
        }
        
    except Exception as e:
        logs.append(log_message(f"–û—à–∏–±–∫–∞: {str(e)}", "ERROR"))
        return {"success": False, "logs": logs, "error": str(e)}

def check_kaspi_availability():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –≤—ã–±–æ—Ä–æ–º –º–µ—Ç–æ–¥–∞"""
    logs = []
    logs.append(log_message("=== KASPI MONITOR START ==="))
    
    result = None
    if USE_SCRAPER_API and SCRAPER_API_KEY:
        logs.append(log_message("–ú–µ—Ç–æ–¥: ScraperAPI"))
        result = check_with_scraper_api()
    else:
        logs.append(log_message("–ú–µ—Ç–æ–¥: –ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å"))
        result = check_direct()
    
    all_logs = logs + result.get("logs", [])
    result["logs"] = all_logs
    result["logs_text"] = "".join(all_logs)
    result["url"] = KASPI_URL
    result["timestamp"] = datetime.now().isoformat()
    
    if result.get("success") and result.get("in_stock") and SEND_EMAIL:
        email_result = send_email_notification(
            "üéâ –¢–æ–≤–∞—Ä –ø–æ—è–≤–∏–ª—Å—è –Ω–∞ Kaspi!",
            f"–¢–æ–≤–∞—Ä '{result.get('product_name')}' —Ç–µ–ø–µ—Ä—å –≤ –Ω–∞–ª–∏—á–∏–∏!\n\n–¶–µ–Ω–∞: {result.get('price')}\n\n–°—Å—ã–ª–∫–∞: {KASPI_URL}"
        )
        result["logs"].append(log_message(email_result))
        result["logs_text"] = "".join(result["logs"])
    
    return result

class handler(BaseHTTPRequestHandler):
    def do_GET(self):
        parsed_url = urlparse(self.path)
        params = parse_qs(parsed_url.query)
        provided_key = params.get('key', [None])[0]
        
        if not API_KEY:
            self.send_response(500)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            self.wfile.write(json.dumps({"error": "API_KEY not configured"}, ensure_ascii=False).encode())
            return
        
        if provided_key != API_KEY:
            self.send_response(403)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            self.wfile.write(json.dumps({"error": "Invalid API key"}, ensure_ascii=False).encode())
            return
        
        result = check_kaspi_availability()
        
        self.send_response(200)
        self.send_header('Content-type', 'application/json; charset=utf-8')
        self.end_headers()
        self.wfile.write(json.dumps(result, ensure_ascii=False, indent=2).encode())
        return
