# api/check.py - –í–µ—Ä—Å–∏—è —Å–æ ScraperAPI
from http.server import BaseHTTPRequestHandler
import requests
import json
from datetime import datetime
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import os
from urllib.parse import urlparse, parse_qs, quote
from bs4 import BeautifulSoup

# –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
KASPI_URL = os.getenv("KASPI_URL")
EMAIL_FROM = os.getenv("EMAIL_FROM")
EMAIL_TO = os.getenv("EMAIL_TO")
EMAIL_PASSWORD = os.getenv("EMAIL_PASSWORD")
API_KEY = os.getenv("API_KEY")
SCRAPER_API_KEY = os.getenv("SCRAPER_API_KEY")  # –ù–æ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è!
SEND_EMAIL = os.getenv("SEND_EMAIL", "true").lower() == "true"
USE_SCRAPER_API = os.getenv("USE_SCRAPER_API", "true").lower() == "true"

def log_message(message, level="INFO"):
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    return f"[{timestamp}] [{level}] {message}\n"

def send_email_notification(subject, body):
    if not SEND_EMAIL or not all([EMAIL_FROM, EMAIL_TO, EMAIL_PASSWORD]):
        return "Email –æ—Ç–∫–ª—é—á–µ–Ω –∏–ª–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"
    
    try:
        msg = MIMEMultipart("alternative")
        msg["Subject"] = subject
        msg["From"] = EMAIL_FROM
        msg["To"] = EMAIL_TO
        
        html_body = f"""
        <html>
          <body style="font-family: Arial, sans-serif; padding: 20px;">
            <h2 style="color: #4CAF50;">üéâ {subject}</h2>
            <p style="font-size: 16px;">{body}</p>
            <hr style="margin: 20px 0;">
            <p>
              <a href="{KASPI_URL}" 
                 style="background-color: #4CAF50; color: white; 
                        padding: 12px 24px; text-decoration: none; 
                        border-radius: 5px; display: inline-block;">
                –û—Ç–∫—Ä—ã—Ç—å –Ω–∞ Kaspi.kz
              </a>
            </p>
            <p style="color: #666; font-size: 12px; margin-top: 20px;">
              {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
            </p>
          </body>
        </html>
        """
        
        msg.attach(MIMEText(body, "plain", "utf-8"))
        msg.attach(MIMEText(html_body, "html", "utf-8"))
        
        server = smtplib.SMTP_SSL("smtp.gmail.com", 465)
        server.login(EMAIL_FROM, EMAIL_PASSWORD)
        server.sendmail(EMAIL_FROM, EMAIL_TO, msg.as_string())
        server.quit()
        
        return "‚úÖ Email –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω"
    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ email: {str(e)}"

def check_with_scraper_api():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ ScraperAPI - –æ–±—Ö–æ–¥–∏—Ç –ª—é–±—É—é –∑–∞—â–∏—Ç—É"""
    logs = []
    logs.append(log_message("–ò—Å–ø–æ–ª—å–∑—É–µ–º ScraperAPI –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏"))
    
    if not SCRAPER_API_KEY:
        logs.append(log_message("SCRAPER_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω", "ERROR"))
        return {"success": False, "logs": logs, "error": "ScraperAPI key not configured"}
    
    try:
        # ScraperAPI - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã!
        api_url = "https://api.scraperapi.com"
        
        # –¢–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è FREE –ø–ª–∞–Ω–∞
        params = {
            "api_key": SCRAPER_API_KEY,
            "url": KASPI_URL
            # –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º: render, country_code, premium_proxy –∏ –¥—Ä.
        }
        
        logs.append(log_message(f"–û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ ScraperAPI (FREE plan)..."))
        logs.append(log_message(f"API Key preview: {SCRAPER_API_KEY[:10]}***"))
        logs.append(log_message(f"Target URL: {KASPI_URL}"))
        
        response = requests.get(api_url, params=params, timeout=60)
        logs.append(log_message(f"–°—Ç–∞—Ç—É—Å: {response.status_code}"))
        
        if response.status_code == 403:
            logs.append(log_message("‚ö†Ô∏è –û—à–∏–±–∫–∞ 403 - –ø—Ä–æ–±–ª–µ–º–∞ —Å API –∫–ª—é—á–æ–º", "ERROR"))
            logs.append(log_message("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:", "ERROR"))
            logs.append(log_message("1. –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å API –∫–ª—é—á–∞", "ERROR"))
            logs.append(log_message("2. –ù–∞–ª–∏—á–∏–µ credits –≤ –∞–∫–∫–∞—É–Ω—Ç–µ", "ERROR"))
            logs.append(log_message("3. https://dashboard.scraperapi.com/", "ERROR"))
            return {"success": False, "logs": logs, "error": "Invalid ScraperAPI key or no credits"}
        
        if response.status_code == 422:
            logs.append(log_message("‚ö†Ô∏è –û—à–∏–±–∫–∞ 422 - –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å", "ERROR"))
            return {"success": False, "logs": logs, "error": "Invalid request parameters"}
        
        if response.status_code != 200:
            error_text = response.text[:300] if response.text else "No error message"
            logs.append(log_message(f"ScraperAPI error: {error_text}", "ERROR"))
            return {"success": False, "logs": logs, "error": f"ScraperAPI returned {response.status_code}"}
        
        logs.append(log_message("‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω–∞"))
        logs.append(log_message(f"–†–∞–∑–º–µ—Ä –æ—Ç–≤–µ—Ç–∞: {len(response.text)} –±–∞–π—Ç"))
        logs.append(log_message("–ü–∞—Ä—Å–∏–º HTML..."))
        
        soup = BeautifulSoup(response.text, "html.parser")
        
        # –ò—â–µ–º JSON-LD –¥–∞–Ω–Ω—ã–µ
        data_block = soup.find("script", {"type": "application/ld+json"})
        
        if not data_block:
            logs.append(log_message("JSON-–±–ª–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã...", "WARNING"))
            
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ 1: Meta —Ç–µ–≥–∏
            title = soup.find("meta", {"property": "og:title"})
            price_meta = soup.find("meta", {"property": "product:price:amount"})
            
            if title:
                product_name = title.get("content", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä")
                logs.append(log_message(f"–ù–∞–π–¥–µ–Ω —Ç–æ–≤–∞—Ä —á–µ—Ä–µ–∑ meta: {product_name}"))
                
                # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–∞–ª–∏—á–∏–∏
                availability_text = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                # –ò—â–µ–º –∫–Ω–æ–ø–∫—É "–ö—É–ø–∏—Ç—å" –∏–ª–∏ —Ç–µ–∫—Å—Ç "–í –Ω–∞–ª–∏—á–∏–∏"
                buy_button = soup.find("button", {"data-role": "add-to-cart"})
                if buy_button:
                    availability_text = "–í –Ω–∞–ª–∏—á–∏–∏"
                    in_stock = True
                else:
                    in_stock = False
                
                return {
                    "success": True,
                    "in_stock": in_stock,
                    "product_name": product_name,
                    "price": price_meta.get("content") if price_meta else "–ù–µ —É–∫–∞–∑–∞–Ω–∞",
                    "availability": availability_text,
                    "method": "scraperapi-meta",
                    "logs": logs
                }
            
            return {"success": False, "logs": logs, "error": "Could not find product data"}
        
        logs.append(log_message("JSON-–±–ª–æ–∫ –Ω–∞–π–¥–µ–Ω, –ø–∞—Ä—Å–∏–º..."))
        data = json.loads(data_block.text)
        
        product_name = data.get("name", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä")
        offers = data.get("offers", {})
        price = offers.get("price", "–ù–µ —É–∫–∞–∑–∞–Ω–∞")
        currency = offers.get("priceCurrency", "")
        availability = offers.get("availability", "")
        
        in_stock = "InStock" in availability
        
        logs.append(log_message(f"üì¶ –¢–æ–≤–∞—Ä: {product_name}"))
        logs.append(log_message(f"üí∞ –¶–µ–Ω–∞: {price} {currency}"))
        logs.append(log_message(f"üìä –°—Ç–∞—Ç—É—Å: {availability}"))
        
        if in_stock:
            logs.append(log_message("‚úÖ –¢–û–í–ê–† –í –ù–ê–õ–ò–ß–ò–ò!", "SUCCESS"))
        else:
            logs.append(log_message("‚ùå –¢–æ–≤–∞—Ä–∞ –Ω–µ—Ç –≤ –Ω–∞–ª–∏—á–∏–∏", "INFO"))
        
        return {
            "success": True,
            "in_stock": in_stock,
            "product_name": product_name,
            "price": f"{price} {currency}",
            "availability": availability,
            "method": "scraperapi",
            "logs": logs
        }
        
    except requests.exceptions.Timeout:
        logs.append(log_message("–¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –∫ ScraperAPI (60 —Å–µ–∫)", "ERROR"))
        return {"success": False, "logs": logs, "error": "ScraperAPI timeout"}
    except json.JSONDecodeError as e:
        logs.append(log_message(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {str(e)}", "ERROR"))
        return {"success": False, "logs": logs, "error": "JSON parse error"}
    except Exception as e:
        logs.append(log_message(f"–û—à–∏–±–∫–∞: {str(e)}", "ERROR"))
        return {"success": False, "logs": logs, "error": str(e)}

def check_direct(retry_count=0):
    """–ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ headers (–∑–∞–ø–∞—Å–Ω–æ–π –º–µ—Ç–æ–¥)"""
    logs = []
    logs.append(log_message(f"–ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å –∫ Kaspi (–ø–æ–ø—ã—Ç–∫–∞ {retry_count + 1})"))
    
    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ headers
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
        "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
        "Accept-Encoding": "gzip, deflate, br, zstd",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "Sec-Fetch-Dest": "document",
        "Sec-Fetch-Mode": "navigate",
        "Sec-Fetch-Site": "none",
        "Sec-Fetch-User": "?1",
        "Cache-Control": "max-age=0",
        "sec-ch-ua": '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"',
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": '"Windows"'
    }
    
    try:
        import time
        if retry_count > 0:
            wait_time = retry_count * 5
            logs.append(log_message(f"–û–∂–∏–¥–∞–Ω–∏–µ {wait_time} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π..."))
            time.sleep(wait_time)
        else:
            time.sleep(2)
        
        session = requests.Session()
        session.headers.update(headers)
        
        logs.append(log_message("–û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å..."))
        r = session.get(KASPI_URL, timeout=20, allow_redirects=True)
        logs.append(log_message(f"–°—Ç–∞—Ç—É—Å: {r.status_code}"))
        
        if r.status_code == 429:
            if retry_count < 2:
                logs.append(log_message("Rate limit, –ø–æ–≤—Ç–æ—Ä—è–µ–º —á–µ—Ä–µ–∑ 5 —Å–µ–∫...", "WARNING"))
                return check_direct(retry_count + 1)
            else:
                logs.append(log_message("‚ö†Ô∏è Rate limit –ø–æ—Å–ª–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—ã—Ç–æ–∫", "ERROR"))
                return {"success": False, "logs": logs, "error": "Rate limit exceeded after retries"}
        
        if r.status_code == 403:
            logs.append(log_message("‚ùå –î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω (403)", "ERROR"))
            return {"success": False, "logs": logs, "error": "Access forbidden (403)"}
        
        if r.status_code != 200:
            return {"success": False, "logs": logs, "error": f"Status {r.status_code}"}
        
        soup = BeautifulSoup(r.text, "html.parser")
        data_block = soup.find("script", {"type": "application/ld+json"})
        
        if not data_block:
            return {"success": False, "logs": logs, "error": "JSON block not found"}
        
        data = json.loads(data_block.text)
        product_name = data.get("name", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä")
        offers = data.get("offers", {})
        price = offers.get("price", "")
        currency = offers.get("priceCurrency", "")
        availability = offers.get("availability", "")
        in_stock = "InStock" in availability
        
        logs.append(log_message(f"–¢–æ–≤–∞—Ä: {product_name}"))
        logs.append(log_message(f"–¶–µ–Ω–∞: {price} {currency}"))
        logs.append(log_message("‚úÖ –í –Ω–∞–ª–∏—á–∏–∏" if in_stock else "‚ùå –ù–µ—Ç –≤ –Ω–∞–ª–∏—á–∏–∏"))
        
        return {
            "success": True,
            "in_stock": in_stock,
            "product_name": product_name,
            "price": f"{price} {currency}",
            "availability": availability,
            "method": "direct",
            "logs": logs
        }
        
    except Exception as e:
        logs.append(log_message(f"–û—à–∏–±–∫–∞: {str(e)}", "ERROR"))
        return {"success": False, "logs": logs, "error": str(e)}

def check_kaspi_availability():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –≤—ã–±–æ—Ä–æ–º –º–µ—Ç–æ–¥–∞"""
    logs = []
    logs.append(log_message("=== KASPI MONITOR START ==="))
    logs.append(log_message(f"URL: {KASPI_URL}"))
    
    result = None
    
    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1: ScraperAPI (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω –∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω)
    if USE_SCRAPER_API and SCRAPER_API_KEY:
        logs.append(log_message("–ú–µ—Ç–æ–¥: ScraperAPI (–æ–±—Ö–æ–¥ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫)"))
        result = check_with_scraper_api()
    else:
        logs.append(log_message("ScraperAPI –æ—Ç–∫–ª—é—á–µ–Ω –∏–ª–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω", "WARNING"))
        logs.append(log_message("–ú–µ—Ç–æ–¥: –ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å"))
        result = check_direct()
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ª–æ–≥–∏
    all_logs = logs + result.get("logs", [])
    result["logs"] = all_logs
    result["logs_text"] = "".join(all_logs)
    result["url"] = KASPI_URL
    result["timestamp"] = datetime.now().isoformat()
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º email –µ—Å–ª–∏ —Ç–æ–≤–∞—Ä –≤ –Ω–∞–ª–∏—á–∏–∏
    if result.get("success") and result.get("in_stock") and SEND_EMAIL:
        email_result = send_email_notification(
            "üéâ –¢–æ–≤–∞—Ä –ø–æ—è–≤–∏–ª—Å—è –Ω–∞ Kaspi!",
            f"–¢–æ–≤–∞—Ä '{result.get('product_name')}' —Ç–µ–ø–µ—Ä—å –≤ –Ω–∞–ª–∏—á–∏–∏!\n\n–¶–µ–Ω–∞: {result.get('price')}\n\n–°—Å—ã–ª–∫–∞: {KASPI_URL}"
        )
        result["logs"].append(log_message(email_result))
        result["logs_text"] = "".join(result["logs"])
        result["email_sent"] = "sent" in email_result
    
    return result

class handler(BaseHTTPRequestHandler):
    def do_GET(self):
        parsed_url = urlparse(self.path)
        params = parse_qs(parsed_url.query)
        provided_key = params.get('key', [None])[0]
        
        if not API_KEY:
            self.send_response(500)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            response = {"error": "API_KEY not configured"}
            self.wfile.write(json.dumps(response, ensure_ascii=False, indent=2).encode())
            return
        
        if provided_key != API_KEY:
            self.send_response(403)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            response = {"error": "Invalid API key"}
            self.wfile.write(json.dumps(response, ensure_ascii=False, indent=2).encode())
            return
        
        result = check_kaspi_availability()
        
        self.send_response(200)
        self.send_header('Content-type', 'application/json; charset=utf-8')
        self.end_headers()
        self.wfile.write(json.dumps(result, ensure_ascii=False, indent=2).encode())
        return
